"""
LangGraph-based ClickHouse Analytics Agent.

Architecture:
  - LLM  : Claude Sonnet 4.6 via OpenRouter (ChatOpenAI adapter)
  - Graph : LangGraph create_react_agent (tool-calling loop)
  - Memory: SqliteSaver checkpointer â€” persists full conversation per session_id
  - Tools : list_tables, clickhouse_query, python_analysis

Session isolation:
  Every API request carries a session_id (= LangGraph thread_id).
  SqliteSaver stores the message state keyed by thread_id.
  Multiple concurrent sessions do NOT interfere with each other.
"""

import json
import time
import sqlite3
from typing import Optional

from langchain_core.messages import AIMessage, HumanMessage, SystemMessage, ToolMessage
from langchain_openai import ChatOpenAI
from langgraph.checkpoint.sqlite import SqliteSaver
from langgraph.prebuilt import create_react_agent

from config import (
    DB_PATH,
    MAX_AGENT_ITERATIONS,
    MAX_TOKENS,
    MODEL,
    OPENROUTER_API_KEY,
    TEMP_DIR,
    TEMP_FILE_TTL_SECONDS,
)
from tools import TOOLS

# â”€â”€â”€ System Prompt â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SYSTEM_PROMPT = """Ð¢Ñ‹ â€” Ð¾Ð¿Ñ‹Ñ‚Ð½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸Ðº Ñ€ÐµÐºÐ»Ð°Ð¼Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…. Ð¢Ñ‹ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑˆÑŒ Ñ Ð±Ð°Ð·Ð¾Ð¹ Ð´Ð°Ð½Ð½Ñ‹Ñ… ClickHouse, ÐºÐ¾Ñ‚Ð¾Ñ€Ð°Ñ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¾ Ñ€ÐµÐºÐ»Ð°Ð¼Ð½Ñ‹Ñ… ÐºÐ°Ð¼Ð¿Ð°Ð½Ð¸ÑÑ…, Ð²Ð¸Ð·Ð¸Ñ‚Ð°Ñ… Ð½Ð° ÑÐ°Ð¹Ñ‚, Ð²Ð¸Ñ‚Ñ€Ð¸Ð½Ð°Ñ… Ð¸ Ð¼Ð°Ñ€ÐºÐµÑ‚Ð¸Ð½Ð³Ð¾Ð²Ñ‹Ñ… Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ°Ñ…. Ð¢Ñ‹ Ð¿Ð¾Ð¼Ð¾Ð³Ð°ÐµÑˆÑŒ Ð¼Ð°Ñ€ÐºÐµÑ‚Ð¾Ð»Ð¾Ð³Ð°Ð¼ Ð¾Ñ‚Ð²ÐµÑ‡Ð°Ñ‚ÑŒ Ð½Ð° Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹, ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÑŒ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ñ‹ Ð¸ ÑÑ‡Ð¸Ñ‚Ð°Ñ‚ÑŒ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ Ð¿Ð¾ÐºÐ°Ð·Ð°Ñ‚ÐµÐ»Ð¸.

## Ð Ð°Ð±Ð¾Ñ‡Ð¸Ð¹ Ð¿Ñ€Ð¾Ñ†ÐµÑÑ (Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÑÐ¹ ÑÑ‚Ñ€Ð¾Ð³Ð¾ Ð¿Ð¾ Ð¿Ð¾Ñ€ÑÐ´ÐºÑƒ):

### 1. ÐŸÐ¾Ð½ÑÑ‚ÑŒ Ð·Ð°Ð¿Ñ€Ð¾Ñ
ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»Ð¸: ÐºÐ°ÐºÐ¸Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð½ÑƒÐ¶Ð½Ñ‹, Ð½ÑƒÐ¶Ð½Ð° Ð»Ð¸ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ, Ð½ÑƒÐ¶Ð½Ð° Ð»Ð¸ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð°, ÐºÐ°ÐºÐ¸Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ ÑÑ‡Ð¸Ñ‚Ð°Ñ‚ÑŒ.

### 2. Ð˜Ð·ÑƒÑ‡Ð¸Ñ‚ÑŒ ÑÑ…ÐµÐ¼Ñƒ (Ð¢ÐžÐ›Ð¬ÐšÐž Ð¿Ñ€Ð¸ Ð¿ÐµÑ€Ð²Ð¾Ð¼ Ð·Ð°Ð¿Ñ€Ð¾ÑÐµ Ð² ÑÐµÑÑÐ¸Ð¸)
Ð•ÑÐ»Ð¸ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð° Ñ‚Ð°Ð±Ð»Ð¸Ñ† ÐµÑ‰Ñ‘ Ð½ÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð° â€” Ð²Ñ‹Ð·Ð¾Ð²Ð¸ `list_tables`.
Ð•ÑÐ»Ð¸ Ð¾Ð½Ð° ÑƒÐ¶Ðµ Ð¸Ð·Ð²ÐµÑÑ‚Ð½Ð° Ð¸Ð· Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð° â€” ÐŸÐ ÐžÐŸÐ£Ð¡Ð¢Ð˜ ÑÑ‚Ð¾Ñ‚ ÑˆÐ°Ð³.

### 3. Ð’Ñ‹Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¸Ð· ClickHouse
Ð’Ñ‹Ð·Ð¾Ð²Ð¸ `clickhouse_query` Ñ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¼ SQL:
- ÐÐ³Ñ€ÐµÐ³Ð¸Ñ€ÑƒÐ¹ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¿Ñ€ÑÐ¼Ð¾ Ð² SQL (SUM, COUNT, AVG, GROUP BY) â€” ClickHouse Ð¾Ñ‡ÐµÐ½ÑŒ Ð±Ñ‹ÑÑ‚Ñ€
- Ð¤Ð¸Ð»ÑŒÑ‚Ñ€ÑƒÐ¹ Ð² WHERE â€” Ð½Ðµ Ð²Ñ‹Ð³Ñ€ÑƒÐ¶Ð°Ð¹ Ð»Ð¸ÑˆÐ½ÐµÐµ
- LIMIT: Ð¾Ð±Ñ‹Ñ‡Ð½Ð¾ 1000â€“10000; Ð´Ð¾ 50000 Ð´Ð»Ñ Ð±Ð¾Ð»ÑŒÑˆÐ¸Ñ… Ð²Ñ‹Ð±Ð¾Ñ€Ð¾Ðº
- Ð¤ÑƒÐ½ÐºÑ†Ð¸Ð¸: toStartOfMonth(), toYear(), toDayOfWeek(), arrayJoin() Ð¸ Ñ‚.Ð´.
- Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸ `parquet_path` Ð¸Ð· Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð´Ð»Ñ python_analysis

### 4. ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð² Python
Ð’Ñ‹Ð·Ð¾Ð²Ð¸ `python_analysis` Ð´Ð»Ñ Ñ€Ð°ÑÑ‡Ñ‘Ñ‚Ð¾Ð² Ð¸ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸:
- Ð¡Ñ‚Ñ€Ð¾Ð¹ Ð³Ñ€Ð°Ñ„Ð¸ÐºÐ¸ (bar, line, pie, scatter, heatmap)
- Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐ¹ Markdown-Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹
- Ð¡Ñ‡Ð¸Ñ‚Ð°Ð¹ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ (CTR, CPC, CPM, ROAS, CR, CPA)
- Ð£ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°Ð¹ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½ÑƒÑŽ `result` Ñ Ð¸Ñ‚Ð¾Ð³Ð¾Ð²Ñ‹Ð¼ Markdown-Ð²Ñ‹Ð²Ð¾Ð´Ð¾Ð¼

### 5. Ð¡Ñ„Ð¾Ñ€Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚
Ð”Ð°Ð¹ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð²Ñ‹Ð²Ð¾Ð´ Ñ Ñ†Ð¸Ñ„Ñ€Ð°Ð¼Ð¸, ÑÑ€Ð°Ð²Ð½ÐµÐ½Ð¸ÑÐ¼Ð¸ Ð¸ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸ÑÐ¼Ð¸.

---

## ÐŸÑ€Ð°Ð²Ð¸Ð»Ð° Python-ÐºÐ¾Ð´Ð°:
1. `df` ÑƒÐ¶Ðµ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½ â€” ÐÐ• Ð²Ñ‹Ð·Ñ‹Ð²Ð°Ð¹ pd.read_parquet()
2. Ð’Ð¡Ð•Ð“Ð”Ð ÑƒÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°Ð¹ `result` (Markdown ÑÑ‚Ñ€Ð¾ÐºÐ° Ñ Ð¸Ñ‚Ð¾Ð³Ð¾Ð¼)
3. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ print() Ð´Ð»Ñ Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ ÑˆÐ°Ð³Ð¾Ð²: print("ðŸ“Š Ð¨Ð°Ð³ 1: ...")
4. ÐŸÐ¾Ð´Ð¿Ð¸ÑÑ‹Ð²Ð°Ð¹ Ð³Ñ€Ð°Ñ„Ð¸ÐºÐ¸ Ð½Ð° Ð Ð£Ð¡Ð¡ÐšÐžÐœ: plt.title(), plt.xlabel(), plt.ylabel()
5. Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€ÑƒÐ¹ Ñ‡Ð¸ÑÐ»Ð°: f"{value:,.0f}" (Ñ†ÐµÐ»Ñ‹Ðµ), f"{value:,.2f}" (Ð´Ñ€Ð¾Ð±Ð½Ñ‹Ðµ)
6. ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°Ð¹ Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ¸: df.dropna() Ð¸Ð»Ð¸ df.fillna(0)
7. Ð”Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ Ð³Ñ€Ð°Ñ„Ð¸ÐºÐ° â€” plt.tight_layout() Ð¿ÐµÑ€ÐµÐ´ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ð¼

## Ð ÐµÐºÐ»Ð°Ð¼Ð½Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸:
- **CTR** = ÐºÐ»Ð¸ÐºÐ¸ / Ð¿Ð¾ÐºÐ°Ð·Ñ‹ Ã— 100%
- **CPC** = Ñ€Ð°ÑÑ…Ð¾Ð´ / ÐºÐ»Ð¸ÐºÐ¸
- **CPM** = Ñ€Ð°ÑÑ…Ð¾Ð´ / Ð¿Ð¾ÐºÐ°Ð·Ñ‹ Ã— 1000
- **CPA** = Ñ€Ð°ÑÑ…Ð¾Ð´ / ÐºÐ¾Ð½Ð²ÐµÑ€ÑÐ¸Ð¸
- **ROAS** = Ð´Ð¾Ñ…Ð¾Ð´ / Ñ€Ð°ÑÑ…Ð¾Ð´ Ã— 100%
- **CR** = ÐºÐ¾Ð½Ð²ÐµÑ€ÑÐ¸Ð¸ / ÐºÐ»Ð¸ÐºÐ¸ Ã— 100%

## Ð¡Ñ‚Ð¸Ð»ÑŒ Ð¾Ñ‚Ð²ÐµÑ‚Ð°:
- Markdown: Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¸ ##/###, Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹, ÑÐ¿Ð¸ÑÐºÐ¸
- Ð­Ð¼Ð¾Ð´Ð·Ð¸ Ð´Ð»Ñ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ: ðŸ“Š ðŸ“ˆ ðŸ“‰ ðŸ’° âœ… âš ï¸
- Ð§Ð¸ÑÐ»Ð° Ñ Ñ€Ð°Ð·Ð´ÐµÐ»Ð¸Ñ‚ÐµÐ»ÑÐ¼Ð¸ Ñ‚Ñ‹ÑÑÑ‡
- Ð¯Ð·Ñ‹Ðº â€” Ñ€ÑƒÑÑÐºÐ¸Ð¹
- ÐšÐ¾Ð½ÐºÑ€ÐµÑ‚Ð¸ÐºÐ°: Ñ†Ð¸Ñ„Ñ€Ñ‹, Ð´Ð¸Ð½Ð°Ð¼Ð¸ÐºÐ°, ÑÑ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ Ñ Ð½Ð¾Ñ€Ð¼Ð¾Ð¹
"""


class AnalyticsAgent:
    """
    Wraps LangGraph ReAct agent with:
      - Claude Sonnet 4.6 via OpenRouter
      - SqliteSaver for session memory
      - Helper methods to extract plots and tool-call logs from agent output
    """

    def __init__(self) -> None:
        if not OPENROUTER_API_KEY:
            raise ValueError(
                "OPENROUTER_API_KEY is not set in .env. "
                "Get your key at https://openrouter.ai"
            )

        # â”€â”€ LLM via OpenRouter â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        self.llm = ChatOpenAI(
            model=MODEL,
            api_key=OPENROUTER_API_KEY,
            base_url="https://openrouter.ai/api/v1",
            max_tokens=MAX_TOKENS,
            default_headers={
                "HTTP-Referer": "https://server.asktab.ru",
                "X-Title": "ClickHouse Analytics Agent",
            },
        )

        # â”€â”€ SqliteSaver checkpointer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Keeps conversation state per thread_id (= session_id).
        # Thread-safe for concurrent requests.
        conn = sqlite3.connect(str(DB_PATH), check_same_thread=False)
        self.memory = SqliteSaver(conn)


        # â”€â”€ LangGraph ReAct agent â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # state_modifier prepends the system prompt before every LLM call
        # (not stored in the checkpoint â€” safe and clean).
        self.graph = create_react_agent(
            model=self.llm,
            tools=TOOLS,
            prompt=SystemMessage(content=SYSTEM_PROMPT),
            checkpointer=self.memory,
        )

        print(f"âœ… AnalyticsAgent ready | model: {MODEL} | db: {DB_PATH}")

    # â”€â”€â”€ Public API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def analyze(self, user_query: str, session_id: str) -> dict:
        """
        Process a user analytics query for a given session.

        Args:
            user_query: The user's question or request.
            session_id: Unique session identifier (= LangGraph thread_id).
                        Reuse the same session_id across requests to maintain context.

        Returns:
            {
              "success":    bool,
              "session_id": str,
              "text_output": str,         # Final Markdown text from the agent
              "plots":      list[str],    # base64 PNG data URIs from python_analysis
              "tool_calls": list[dict],   # Log of tool invocations
              "error":      str | None,
            }
        """
        config = {"configurable": {"thread_id": session_id}}

        try:
            # LangGraph invoke â€” sends only the NEW message;
            # history is loaded automatically from SqliteSaver by thread_id.
            result = self.graph.invoke(
                {"messages": [HumanMessage(content=user_query)]},
                config=config,
            )

            messages: list = result.get("messages", [])

            text_output = self._extract_final_text(messages)
            plots = self._extract_plots(messages)
            tool_calls = self._extract_tool_calls(messages)

            return {
                "success": True,
                "session_id": session_id,
                "text_output": text_output,
                "plots": plots,
                "tool_calls": tool_calls,
                "error": None,
            }

        except Exception as exc:
            import traceback as tb
            return {
                "success": False,
                "session_id": session_id,
                "text_output": "",
                "plots": [],
                "tool_calls": [],
                "error": str(exc),
                "traceback": tb.format_exc(),
            }

    def get_session_info(self, session_id: str) -> dict:
        """Return basic metadata about a session."""
        try:
            config = {"configurable": {"thread_id": session_id}}
            state = self.graph.get_state(config)
            msgs = state.values.get("messages", []) if state and state.values else []
            # Count only user-visible exchanges (HumanMessage + AIMessage pairs)
            user_msgs = sum(1 for m in msgs if isinstance(m, HumanMessage))
            return {
                "session_id": session_id,
                "total_messages": len(msgs),
                "user_turns": user_msgs,
                "has_history": user_msgs > 0,
            }
        except Exception:
            return {
                "session_id": session_id,
                "total_messages": 0,
                "user_turns": 0,
                "has_history": False,
            }

    def cleanup_temp_files(self) -> int:
        """Delete Parquet files older than TEMP_FILE_TTL_SECONDS. Returns count deleted."""
        cutoff = time.time() - TEMP_FILE_TTL_SECONDS
        deleted = 0
        for f in TEMP_DIR.glob("*.parquet"):
            try:
                if f.stat().st_mtime < cutoff:
                    f.unlink()
                    deleted += 1
            except OSError:
                pass
        if deleted:
            print(f"ðŸ—‘ï¸  Deleted {deleted} expired parquet file(s)")
        return deleted

    # â”€â”€â”€ Private helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _extract_final_text(self, messages: list) -> str:
        """Return content of the last AIMessage that has non-empty text."""
        for msg in reversed(messages):
            if not isinstance(msg, AIMessage):
                continue
            content = msg.content
            if isinstance(content, str) and content.strip():
                return content
            # Some models return list of content blocks
            if isinstance(content, list):
                parts = [
                    block["text"]
                    for block in content
                    if isinstance(block, dict) and block.get("type") == "text"
                ]
                text = "\n".join(parts).strip()
                if text:
                    return text
        return ""

    def _extract_plots(self, messages: list) -> list[str]:
        """
        Extract base64 PNG plots from python_analysis ToolMessages
        that belong to the CURRENT agent run (after the last HumanMessage).
        """
        # Find index of the most recently added HumanMessage
        last_human_idx = -1
        for i, msg in enumerate(messages):
            if isinstance(msg, HumanMessage):
                last_human_idx = i

        if last_human_idx < 0:
            return []

        plots: list[str] = []
        for msg in messages[last_human_idx:]:
            if not isinstance(msg, ToolMessage):
                continue
            tool_name = getattr(msg, "name", "") or ""
            if tool_name != "python_analysis":
                continue
            try:
                data = json.loads(msg.content)
                if isinstance(data, dict) and data.get("plots"):
                    plots.extend(data["plots"])
            except (json.JSONDecodeError, AttributeError):
                pass

        return plots

    def _extract_tool_calls(self, messages: list) -> list[dict]:
        """
        Extract a compact log of tool calls made during the current run.
        """
        last_human_idx = -1
        for i, msg in enumerate(messages):
            if isinstance(msg, HumanMessage):
                last_human_idx = i

        if last_human_idx < 0:
            return []

        tool_calls: list[dict] = []
        for msg in messages[last_human_idx:]:
            if not isinstance(msg, AIMessage):
                continue
            for tc in getattr(msg, "tool_calls", []):
                name = tc.get("name", "")
                args = tc.get("args", {})
                # Truncate large args for the log
                compact_args = {
                    k: (v[:300] + "â€¦" if isinstance(v, str) and len(v) > 300 else v)
                    for k, v in args.items()
                }
                tool_calls.append({"tool": name, "input": compact_args})

        return tool_calls


# â”€â”€â”€ Global singleton â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_agent: Optional[AnalyticsAgent] = None


def get_agent() -> AnalyticsAgent:
    """Return (or create) the global AnalyticsAgent instance."""
    global _agent
    if _agent is None:
        _agent = AnalyticsAgent()
    return _agent
